{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d91c1b86",
   "metadata": {},
   "source": [
    "## Fundemental Hypotheses\n",
    "\n",
    "Overall, I draw 4 hypotheses:\n",
    "1) If (i) \"no label\" can predict sensitive features with high scores and (ii) \"yes label\" scores similarly to \"no label\", then \"fairness through unawareness\" will not work.\n",
    "\n",
    "    - All we can say is that \"fairness through unawareness\" will not work because we can predict the sensitive features using not sensitive features.\n",
    "    \n",
    "2) If (i) \"no label\" cannot predict sensitive features well and (ii) \"yes label\" scores similarly to \"no label\", then a learning-based algorithm should already be fair regardless of \"fairness through unawareness\".\n",
    "\n",
    "    - If one cannot predict the sensitive features using other features even with labels, then the labels is not correlated to the features at all. One should suspect \"malicous intent\" in this scenario if an algorithm has high AOD/EOD scores.\n",
    "    \n",
    "3) If (i) no label can predict sensitive features with high scores and (ii) \"yes label\" scores even higher than \"no label\", then \"fairness through unawareness\" may help to make the algorithm more fair by a little bit.\n",
    "\n",
    "    - In this case, there are no good solutions. \"Fairness through unawareness\" may help a little but chances are AOD and EOD scores will still be high. \n",
    "    \n",
    "4) If (i) no label cannot predict sensitive features well and (ii) \"yes label\" scores higher than \"no label\", then \"fairness through unawareness\" may help to make the algorithm more fair.\n",
    "\n",
    "    - In this case, there is substantial correlation between label and gender. However, this correlation cannot be predicted or substituted using other sensitive features. Therefore, we expect \"fairness through unawareness\" to work well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a169e9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "import sys\n",
    "sys.path.append(\"./subjects/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9fe7e89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = \"LR\"\n",
    "dataset = \"census\"\n",
    "sensitive_param = \"sex\"\n",
    "from sklearn.covariance import EmpiricalCovariance\n",
    "import sklearn.decomposition\n",
    "import ast\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "# import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from adf_data.census import census_data\n",
    "from adf_data.credit import credit_data\n",
    "from adf_data.bank import bank_data\n",
    "from adf_data.compas import compas_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e8b6b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./Dataset\" + \"/\" + f\"{model}_{dataset}_{sensitive_param}_x100.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed2d058",
   "metadata": {},
   "source": [
    "## Without the label as a feature\n",
    "\n",
    "Here, we are attempting to use the other features in the dataset to label the gender of a person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7799e081",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"census\":census_data, \"credit\":credit_data, \"bank\":bank_data, \"compas\": compas_data}\n",
    "\n",
    "X, Y, input_shape, nb_classes = data[dataset]()\n",
    "Y = X[:,8]\n",
    "X = np.delete(X, 8, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a1883d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.709372312983663"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=10000).fit(X_train, y_train)\n",
    "lr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1001e4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7995332268763051"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "dt.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54fed41c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6692054912318418"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Y)/len(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ac665f",
   "metadata": {},
   "source": [
    "## With the label as a feature\n",
    "Here we do the same -- trying to label each person's gender. However, we add, as a feature, the original label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "845b6e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"census\":census_data, \"credit\":credit_data, \"bank\":bank_data, \"compas\": compas_data}\n",
    "\n",
    "X, Y, input_shape, nb_classes = data[dataset]()\n",
    "Y_feature = np.argmax(Y, axis=1)\n",
    "Y = X[:,8]\n",
    "X = np.delete(X, 8, 1)\n",
    "X = np.insert(X,0, Y_feature, axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2dacb4e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7112148384719322"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=10000).fit(X_train, y_train)\n",
    "lr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14a8c219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.802972607787741"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "dt.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3344d474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef092cdb",
   "metadata": {},
   "source": [
    "We first draw a few factual statements:\n",
    "\n",
    "Fact 1) A learning algorithm, especially a decision tree as compared to a Logistic Regression model, can discrimate someone's gender with ~80% acuracy.\n",
    "\n",
    "Fact 2) Adding the label does not significantly increase the model's ability to discrinate someone's gender.\n",
    "\n",
    "From these statements, we make the following conjectures:\n",
    "\n",
    "Conjecture 1) From Fact 1, I think it is intuitive to hypothesize that \"fairness through unawareness\" may not work well since an algorithm can essentially predict someone's gender anyways.\n",
    "\n",
    "Conjecture 2) From Fact 2, I think that it is intuitive to hypothesize that the features themselves are good enough to be used to predict the gender attribute. Therefore again, \"fairness through unawareness\" may not work well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9d8a86",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3c1d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
